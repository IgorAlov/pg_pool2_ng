## Описание 
В статье описан способ настройки конфигурации PgPOOL-II в качестве балансировщика "читающей" (SELECT) нагрузки PostgreSQL в режиме "Master-Master" используя принципы IP Anycast. 

### Ограничения:
* Все настройки, файлы конфигураций и рекомендации приведены для дистрибутива Debian Linux, и именно для пакетов входящих в стандартную поставку Debian 11. В случае если Вы работаете с другим Linux или пакетами, то Вам будет необходимо внести изменения самостоятельно.
* Мы будем работать с PostgreSQL 13 и PgPOOL-II 4.1, проблем с другими версиями скорее всего не будет, но это не точно.
* У вас уже должен быть настроенный кластер потоковой репликации для PostgreSQL, или Вы знаете как это сделать.
* Вам потребуются минимальные знания сетевого стэка Linux и протокола динамической маршрутизации в частности OSPF, но вы можете все сделать и на BGP зависит от ваших желаний.


## С чего все началась
Много лет я работал в телекоме, и так получилось, что за все время с базой PostgreSQL так и не пришлось всерьез поработать. Но совсем недавно, попав в мир Enterprice,  мне пришлось познакомится с PostgreSQL, и чуть ли не сразу погрузиться в решение проблемы распределения нагрузки между разными экземплярами. Сразу на глаза попались разные решения, в том числе и [PgPOOL-II](https://pgpool.net), [PgCat](https://github.com/levkk/pgcat), [Percona](https://www.percona.com/ha-for-postgresql), но мне пришлось значительно удивится тому, что во всех предлагаемых конфигурациях используется один виртуальный адрес, который "перебрасывается" между нодами с помощью скриптов либо используя keepalived, что на мой взгляд не очень то современно.

### недостатки готовых решений:
* Один виртуальный адрес на всех
   * Независимо от количества нод для балансировки,  весь трафик будет при любом сценарии идти только через одну ноду, на которой в данный момент будет находится виртуальный адрес. Все остальные ноды будут простаивать в ожидании назначения IP адреса, эти ресурсы у нас будут постоянно выделены но не использоваться.
   * Если у нас несколько датаЦентров (например: Санкт-петербург, Москва, Екатеринбург), и по ноде балансировки расположено в каждом из них, то в этом случае трафик может "бегать" между городами впустую занимая дорогостоящую полосу пропускания, в добавок к этому увеличивая время отклика самого приложения.
   * Время переключения ("переноса") адреса в случае сценария выхода из строя одной ноды, заметное для приложения и составляет до 2-10 секунд.








